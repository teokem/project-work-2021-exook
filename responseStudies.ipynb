{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "gentle-demographic",
   "metadata": {},
   "source": [
    "# Trigger Level Analysis Plotting for Response and Resolution studies at the ATLAS Experiment\n",
    "\n",
    "## Abstract\n",
    "The Trigger Level Analysis (TLA) at the ATLAS experiment uses partly reconstructed particle collision events for its analysis. The smaller data size allows TLA to obtain a much larger number of events and a smaller statisitical uncertainty. This notebook presents the data processing and analysis used to verify the smoothness of the TLA calibration as well as the resolution of the analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "automated-prospect",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "When particles collide at the LHC it is possible that new particles are created which decay into decay products. The ATLAS detecor allows us to study the properties of these decay products and learn about the properties of the original particle. Due to the nature of the strong force, the proton-proton collisions at the LHC often one of the most commonly occurring observable objects at ATLAS are the collimated particle showers. From the detector data we can then group the energy deposits of these particle showers into an object called a jet, and by studying these jets we can learn about potential particles created in the collision.\n",
    "\n",
    "Particle collision event data at the Large Hadron Collider (LHC) at CERN uses a specialized data framework and file format called ROOT. For each particle collision event we can acces, among other things, the jets energy and momentum (and direction in the cylindrical coordinates eta and phi). With this we can represent the two \"largest\" jets (highest transverse momentum (pT)) as Lorentz vectors and calculate the invariant mass of the particle formed by the collision (if there is any).\n",
    "\n",
    "Before we run the following code a C++ algorithm has processed millions of simulated particle collision events. With simulated events we can look at the energy and momentum of particles and jets as they would look purley theoretically, called \"truth jets\". We can also simulate each particles propagation and interaction with the different elements of the detector, as well as the detecotr readout to get a so called \"reconstructed jet\". Looking at the ratio the transverse momentum, energy, or invariant mass between the reconstructed jets and truth jets can give us important information about our detector and data processing.\n",
    "\n",
    "The C++ algorithm outputs 3D histograms with response, truth mjj (pT, or energy), truth eta on the x, y, and z axis respectively. This notebook transforms this 3D histogram and transforms it into more understandable plots such as response vs truth mjj using the following steps:\n",
    "\n",
    "* Fitting\n",
    "    * 3D histograms are sliced on the z axis and projected into a 2D histogram (each slice is usuallly a truht eta)\n",
    "    * 2D histograms are sliced in bins on the y axis and projected into 1D histograms (each slice is usuallly a truht pT or truth mjj range/bin width)\n",
    "    * 1D histograms are fitted with a gaussian using an external python script called \"JESBalanceFitter\"\n",
    "    * Information about the gaussian fits are written to disk for future processing\n",
    "* Plotting\n",
    "    * A set of the avaliable fit collections is created, one per initial 3D histogram\n",
    "    * For each 3D histogram the fit mean is plotted at the corresponding 1D histograms pT or mjj bin. Providing a response vs truth mjj plot for all bins"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dimensional-collectible",
   "metadata": {},
   "source": [
    "## Loading the 3D histograms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "sitting-fiber",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to JupyROOT 6.20/00\n"
     ]
    }
   ],
   "source": [
    "import ROOT\n",
    "from array import array\n",
    "from JES_BalanceFitter import JES_BalanceFitter\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mysterious-limit",
   "metadata": {},
   "source": [
    "Initialise parameters for fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "medical-potential",
   "metadata": {},
   "outputs": [],
   "source": [
    "listOfRootFilePaths = [\"/home/pekman/TLA/TH3Files/v14/merged_mc16d_mjj_v14.root\",\n",
    "                       \"/home/pekman/TLA/TH3Files/v15/merged_mc16d_mjj_v15.root\",\n",
    "                       \"/home/pekman/TLA/TH3Files/v18/merged_mc16a_mjj_v18.root\",\n",
    "                       \"/home/pekman/TLA/TH3Files/v19/merged_mc16a_mjj_v19.root\",\n",
    "                      ]\n",
    "\n",
    "graphType = \"response\"\n",
    "\n",
    "slicingAxis = \"z\"\n",
    "slices = [[-2.8,2.8],[-0.6,0.6]]\n",
    "\n",
    "projectionAxis = \"y\"\n",
    "projectionRebinWidth = 1\n",
    "\n",
    "responseAxis = \"x\"\n",
    "\n",
    "nSigmaForFit = 1.3\n",
    "fitOptString = \"RESQ\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "desperate-afternoon",
   "metadata": {},
   "source": [
    "Create an empty dataframe with an entry for each 3D histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "detailed-divide",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scaled_h_-_EM-Online_over_-truth_-_pt_-_eta\n",
      "scaled_h_-_EM-Online_over_-truth_-_mjj_-_eta\n",
      "scaled_h_-_Pileup-Online_over_-truth_-_pt_-_eta\n",
      "scaled_h_-_Pileup-Online_over_-truth_-_mjj_-_eta\n",
      "scaled_h_-_EtaJES-Online_over_-truth_-_pt_-_eta\n",
      "scaled_h_-_EtaJES-Online_over_-truth_-_mjj_-_eta\n",
      "scaled_h_-_GSC-Online_over_-truth_-_pt_-_eta\n",
      "scaled_h_-_GSC-Online_over_-truth_-_mjj_-_eta\n",
      "scaled_h_-_EM-Online_over_-truth_-_pt_-_eta\n",
      "scaled_h_-_EM-Online_over_-truth_-_mjj_-_eta\n",
      "scaled_h_-_Pileup-Online_over_-truth_-_pt_-_eta\n",
      "scaled_h_-_Pileup-Online_over_-truth_-_mjj_-_eta\n",
      "scaled_h_-_EtaJES-Online_over_-truth_-_pt_-_eta\n",
      "scaled_h_-_EtaJES-Online_over_-truth_-_mjj_-_eta\n",
      "scaled_h_-_GSC-Online_over_-truth_-_pt_-_eta\n",
      "scaled_h_-_GSC-Online_over_-truth_-_mjj_-_eta\n",
      "scaled_h_-_EM-Offline_over_-truth_-_pt_-_eta\n",
      "scaled_h_-_EM-Offline_over_-truth_-_mjj_-_eta\n",
      "scaled_h_-_Pileup-Offline_over_-truth_-_pt_-_eta\n",
      "scaled_h_-_Pileup-Offline_over_-truth_-_mjj_-_eta\n",
      "scaled_h_-_EtaJES-Offline_over_-truth_-_pt_-_eta\n",
      "scaled_h_-_EtaJES-Offline_over_-truth_-_mjj_-_eta\n",
      "scaled_h_-_GSC-Offline_over_-truth_-_pt_-_eta\n",
      "scaled_h_-_GSC-Offline_over_-truth_-_mjj_-_eta\n",
      "scaled_h_-_SmearedMomentum-Offline_over_-truth_-_pt_-_eta\n",
      "scaled_h_-_SmearedMomentum-Offline_over_-truth_-_mjj_-_eta\n",
      "scaled_h_-_EM-Offline_over_-truth_-_pt_-_eta\n",
      "scaled_h_-_EM-Offline_over_-truth_-_mjj_-_eta\n",
      "scaled_h_-_Pileup-Offline_over_-truth_-_pt_-_eta\n",
      "scaled_h_-_Pileup-Offline_over_-truth_-_mjj_-_eta\n",
      "scaled_h_-_EtaJES-Offline_over_-truth_-_pt_-_eta\n",
      "scaled_h_-_EtaJES-Offline_over_-truth_-_mjj_-_eta\n",
      "scaled_h_-_GSC-Offline_over_-truth_-_pt_-_eta\n",
      "scaled_h_-_GSC-Offline_over_-truth_-_mjj_-_eta\n",
      "scaled_h_-_SmearedMomentum-Offline_over_-truth_-_pt_-_eta\n",
      "scaled_h_-_SmearedMomentum-Offline_over_-truth_-_mjj_-_eta\n",
      "scaled_h_-_EM-Offline_over_-truth_-_pt_-_eta\n",
      "scaled_h_-_EM-Offline_over_-truth_-_mjj_-_eta\n",
      "scaled_h_-_Pileup-Offline_over_-truth_-_pt_-_eta\n",
      "scaled_h_-_Pileup-Offline_over_-truth_-_mjj_-_eta\n",
      "scaled_h_-_EtaJES-Offline_over_-truth_-_pt_-_eta\n",
      "scaled_h_-_EtaJES-Offline_over_-truth_-_mjj_-_eta\n",
      "scaled_h_-_GSC-Offline_over_-truth_-_pt_-_eta\n",
      "scaled_h_-_GSC-Offline_over_-truth_-_mjj_-_eta\n",
      "scaled_h_-_SmearedMomentum-Offline_over_-truth_-_pt_-_eta\n",
      "scaled_h_-_SmearedMomentum-Offline_over_-truth_-_mjj_-_eta\n",
      "scaled_h_-_EM-Offline_over_-truth_-_pt_-_eta\n",
      "scaled_h_-_EM-Offline_over_-truth_-_mjj_-_eta\n",
      "scaled_h_-_Pileup-Offline_over_-truth_-_pt_-_eta\n",
      "scaled_h_-_Pileup-Offline_over_-truth_-_mjj_-_eta\n",
      "scaled_h_-_EtaJES-Offline_over_-truth_-_pt_-_eta\n",
      "scaled_h_-_EtaJES-Offline_over_-truth_-_mjj_-_eta\n",
      "scaled_h_-_GSC-Offline_over_-truth_-_pt_-_eta\n",
      "scaled_h_-_GSC-Offline_over_-truth_-_mjj_-_eta\n",
      "scaled_h_-_SmearedMomentum-Offline_over_-truth_-_pt_-_eta\n",
      "scaled_h_-_SmearedMomentum-Offline_over_-truth_-_mjj_-_eta\n",
      "scaled_h_-_EM-Online_over_-truth_-_pt_-_eta\n",
      "scaled_h_-_EM-Online_over_-truth_-_mjj_-_eta\n",
      "scaled_h_-_Pileup-Online_over_-truth_-_pt_-_eta\n",
      "scaled_h_-_Pileup-Online_over_-truth_-_mjj_-_eta\n"
     ]
    }
   ],
   "source": [
    "for rootFilePath in listOfRootFilePaths:\n",
    "    inFile = ROOT.TFile.Open(rootFilePath)\n",
    "    \n",
    "    for currentSlice in slices:\n",
    "        inFile = ROOT.TFile.Open(rootFilePath)\n",
    "        listOfKeys = inFile.GetListOfKeys()\n",
    "\n",
    "        l=[]\n",
    "        for key in listOfKeys:\n",
    "            TH3Name = key.GetName()\n",
    "            if TH3Name[0:9] != \"scaled_h_\":\n",
    "                continue\n",
    "            elif inFile.Get(TH3Name).GetEntries()==0.0:\n",
    "                print(\"WARNING:\",TH3Name,\" is empty!\")\n",
    "                continue\n",
    "            else:\n",
    "                l.append(pd.Series({ \"x\"             :[],\n",
    "                                     \"y\"             :[],\n",
    "                                     \"xError\"        :[],\n",
    "                                     \"yError\"        :[],\n",
    "                                     \"sigma\"         :[],\n",
    "                                     \"sigmaError\"    :[],\n",
    "                                     \"sigmaOverY\"    :[],\n",
    "                                     \"fitAmplitude\"  :[],\n",
    "                                     \"fitMin\"        :[],\n",
    "                                     \"fitMax\"        :[],\n",
    "\n",
    "                                     \"TH1BinEdges\"   :[],\n",
    "                                     \"TH1BinEntries\" :[],\n",
    "                                     \"TH1BinErrors\"  :[],\n",
    "                                   },\n",
    "                                      name=TH3Name))\n",
    "        dfPath = rootFilePath.split(\".\")[0]+\"_\"+slicingAxis+\"[\"+str(currentSlice[0])+\",\"+str(currentSlice[1])+\"]\"\n",
    "        df = pd.DataFrame(l)\n",
    "    \n",
    "        for TH3Name in df.index:\n",
    "            print(TH3Name)\n",
    "\n",
    "            inTH3 = inFile.Get(TH3Name)\n",
    "            h3D = inTH3.Clone()\n",
    "\n",
    "            #set JES_BalanceFitter options\n",
    "            JESBfitter = JES_BalanceFitter(nSigmaForFit)\n",
    "            JESBfitter.SetGaus()\n",
    "            JESBfitter.SetFitOpt(fitOptString)\n",
    "\n",
    "            listOfTH1Content=[]\n",
    "            listOfGaussians=[]\n",
    "\n",
    "            xnBins = h3D.GetXaxis().GetNbins()\n",
    "            ynBins = h3D.GetYaxis().GetNbins()\n",
    "\n",
    "            #Get the bin which corresponds to the desired slice axis range\n",
    "            if slicingAxis == \"y\":\n",
    "                h3D.GetYaxis().SetRangeUser(currentSlice[0], currentSlice[1])     \n",
    "            elif slicingAxis == \"z\":\n",
    "                h3D.GetZaxis().SetRangeUser(currentSlice[0], currentSlice[1]) \n",
    "\n",
    "            #Project the 3D histogram with the set y-axis range\n",
    "            h2D=h3D.Project3D(responseAxis + projectionAxis)\n",
    "\n",
    "            #rebin according to the desired rebinningFactor\n",
    "            h2D.RebinX(projectionRebinWidth)\n",
    "\n",
    "            currentRebinnedBin = 1\n",
    "            for currentRebinnedBin in range(1, h2D.GetNbinsX()+1):\n",
    "                #name of projection\n",
    "                projName = \"slice\"+str(currentSlice[0])+\"to\"+str(currentSlice[1])+\"_projectionBin\"+str(h2D.GetXaxis().GetBinLowEdge(currentRebinnedBin))+\"to\"+str(h2D.GetXaxis().GetBinUpEdge(currentRebinnedBin))\n",
    "\n",
    "                #take projection\n",
    "                h1D=h2D.ProjectionY(projName, currentRebinnedBin, currentRebinnedBin)\n",
    "\n",
    "                #skip empty bins\n",
    "                if h1D.GetEntries() == 0:\n",
    "                    #print(\"empty 1D hist, skipping!\")\n",
    "                    continue\n",
    "\n",
    "                #fitting limits\n",
    "                fitMax = h1D.GetMean() + nSigmaForFit * h1D.GetRMS()\n",
    "                fitMin = h1D.GetMean() - nSigmaForFit * h1D.GetRMS()\n",
    "\n",
    "                #obtain fit using JES_BalanceFitter and associate it to the TH1           \n",
    "                JESBfitter.Fit(h1D, fitMin, fitMax)\n",
    "                fit = JESBfitter.GetFit()\n",
    "                histFit = JESBfitter.GetHisto()\n",
    "                Chi2Ndof = JESBfitter.GetChi2Ndof()\n",
    "                histFit.GetListOfFunctions().Add(fit)\n",
    "\n",
    "                binEdges=[]\n",
    "                binEntries=[]\n",
    "                binErrors=[]\n",
    "                for i in range(1, h1D.GetNbinsX()+1):#Plus one to include last bin, this is simple python syntax\n",
    "                  binEdges.append(h1D.GetXaxis().GetBinLowEdge(i))\n",
    "                  binEntries.append(h1D.GetBinContent(i))\n",
    "                  binErrors.append(h1D.GetBinError(i))\n",
    "                binErrors.append(h1D.GetXaxis().GetBinUpEdge(h1D.GetNbinsX()))# Append the right most edge\n",
    "\n",
    "\n",
    "                df[\"x\"].loc[TH3Name].append(float(h2D.GetXaxis().GetBinCenter(currentRebinnedBin)))\n",
    "                df[\"y\"].loc[TH3Name].append(float(fit.GetParameter(1)))\n",
    "                df[\"xError\"].loc[TH3Name].append(float((h2D.GetXaxis().GetBinWidth(currentRebinnedBin)/2.0)))#half bin width\n",
    "                df[\"yError\"].loc[TH3Name].append(float(fit.GetParError(1)))\n",
    "                df[\"sigma\"].loc[TH3Name].append(float(fit.GetParameter(2)))\n",
    "                df[\"sigmaError\"].loc[TH3Name].append(float(fit.GetParError(2)))\n",
    "                try: \n",
    "                    df[\"sigmaOverY\"].loc[TH3Name].append(float(fit.GetParameter(2) / float(fit.GetParameter(1))))\n",
    "                except: \n",
    "                    df[\"sigmaOverY\"].loc[TH3Name].append(0)\n",
    "\n",
    "                df[\"TH1BinEdges\"].loc[TH3Name].append(binEdges)\n",
    "                df[\"TH1BinEntries\"].loc[TH3Name].append(binEntries)\n",
    "                df[\"TH1BinErrors\"].loc[TH3Name].append(binErrors)\n",
    "\n",
    "        \n",
    "        df.to_pickle(dfPath+\".pickle\")\n",
    "\n",
    "    inFile.Close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "after-maldives",
   "metadata": {},
   "source": [
    "## Plotting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "operational-seating",
   "metadata": {},
   "source": [
    "### Response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "executive-flexibility",
   "metadata": {},
   "source": [
    "Make some helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exciting-priest",
   "metadata": {},
   "outputs": [],
   "source": [
    "def isItDataOrMC(rootFilePath):\n",
    "    if(\"MC\" or \"mc\" in rootFilePath.split(\"/\")[-1]): return \"MC\"\n",
    "    elif(\"data\" or \"Data\" or \"DATA\" in rootFilePath.split(\"/\")[-1]): return \"Data\"\n",
    "    else: \"Cannot determine if it is Data or MC\"\n",
    "    \n",
    "def isItOnlineOrOffline(rootFilePath):\n",
    "    if(\"Online\" or \"online\" in rootFilePath.split(\"/\")[-1]): return \"Online\"\n",
    "    elif(\"Offline\" or \"offline\" in rootFilePath.split(\"/\")[-1]): return \"Online\"\n",
    "    else: \"Cannot determine if it is Online or Offline\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "invisible-month",
   "metadata": {},
   "source": [
    "Set plotting parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "steady-bunny",
   "metadata": {},
   "outputs": [],
   "source": [
    "xAxisUnit = \"mjj\"\n",
    "\n",
    "xAxisLabel = \"Truth $\"+xAxisUnit[0]+\"_{\"+xAxisUnit[1:].upper()+\"}$\"\n",
    "yAxisLabel = \"$\"+xAxisUnit[0]+\"_{\"+xAxisUnit[1:].upper()+\"}$ Response\"\n",
    "\n",
    "skipEnergyScales = [\"SmearedMomentum\"]\n",
    "\n",
    "legendTitle = \"Legend\"\n",
    "\n",
    "xLimits = (100,5000)\n",
    "yLimits = (0.99,1.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "latest-wages",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy as scipy\n",
    "import matplotlib.pyplot as plt\n",
    "import mplhep as hep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "classified-trailer",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get data information based on root file path and TH3 name\n",
    "DataOrMC = isItDataOrMC(rootFilePath)\n",
    "OnlineOrOffline = isItOnlineOrOffline(rootFilePath)\n",
    "\n",
    "## Drop unwanted TH3s based on xAxisUnit\n",
    "#df = pd.read_pickle(\"./TH3Dataframe.pickle\")\n",
    "#for TH3Name in df.index:\n",
    "#    if(xAxisUnit not in TH3Name ):\n",
    "#        df.drop(TH3Name, inplace=True)\n",
    "\n",
    "# Initialize figure and padding\n",
    "f, ax = plt.subplots(figsize=(8, 6),sharex=True)\n",
    "f.subplots_adjust(left=0.11, right=0.95, bottom=0.12, top=0.95)\n",
    "\n",
    "# Define markers and colors for plots\n",
    "markers = [\"o\",\"^\",\">\",\"v\",\"<\"]\n",
    "colors = [\"black\",\"crimson\",\"darkorange\",\"dodgerblue\",\"forestgreen\"]\n",
    "\n",
    "\n",
    "for rootFilePath in listOfRootFilePaths:\n",
    "    for currentSlice in slices:\n",
    "        #plt.cla()\n",
    "        #plt.clf()\n",
    "        f, ax = plt.subplots(figsize=(8, 6),sharex=True)\n",
    "        f.subplots_adjust(left=0.11, right=0.95, bottom=0.12, top=0.95)\n",
    "        dfPath = rootFilePath.split(\".\")[0]+\"_\"+slicingAxis+\"[\"+str(currentSlice[0])+\",\"+str(currentSlice[1])+\"]\"\n",
    "        df = pd.read_pickle(dfPath+\".pickle\")\n",
    "        \n",
    "        # Iterate over TH3s in data frame\n",
    "        i=-1\n",
    "        for TH3Name in reversed(df.index):\n",
    "            skipping = False\n",
    "            if xAxisUnit not in TH3Name:\n",
    "                skipping = True\n",
    "            for skippedEnergyScales in skipEnergyScales:\n",
    "                if skippedEnergyScales in TH3Name:\n",
    "                    skipping = True\n",
    "            if skipping: continue\n",
    "            i+=1\n",
    "            print(\"TH3 Name:\",TH3Name,i)\n",
    "\n",
    "            # Get data information based on TH3 name\n",
    "            numeratorEnergyScale = TH3Name.split(\"_-_\")[1].split(\"_\")[0].split(\"-\")[0]\n",
    "            denominatorEnergyScale = TH3Name.split(\"_-_\")[1].split(\"_\")[2].split(\"-\")[0]\n",
    "            if denominatorEnergyScale == \"\":denominatorEnergyScale = TH3Name.split(\"_-_\")[1].split(\"_\")[2].split(\"-\")[1]\n",
    "\n",
    "            # Assign data from dataframe\n",
    "            x=df[\"x\"].loc[TH3Name]\n",
    "            y=df[\"y\"].loc[TH3Name]\n",
    "            x_error=df[\"xError\"].loc[TH3Name]\n",
    "            y_error=df[\"yError\"].loc[TH3Name]\n",
    "\n",
    "            # Plot data\n",
    "            ax.errorbar(x, y, yerr=y_error, xerr=x_error,\n",
    "                        linestyle='None',\n",
    "                        marker=markers[i],\n",
    "                        color=colors[i],\n",
    "                        markersize=2,\n",
    "                        linewidth=0.5,\n",
    "                        label=numeratorEnergyScale+\"$_{\"+xAxisUnit+\"}$\"+\" / \"+denominatorEnergyScale+\"$_{\"+xAxisUnit+\"}$\",\n",
    "                       )\n",
    "\n",
    "        # Add legend\n",
    "        leg = ax.legend(borderpad=0.5, loc=1, ncol=2, frameon=True,facecolor=\"white\",framealpha=1)\n",
    "        leg._legend_box.align = \"right\"\n",
    "        leg.set_title(legendTitle)#+\"\\nFit range:[\"+str(round(x[0],0))+\", \"+str(round(x[-1],0))+\"] GeV\")\n",
    "\n",
    "        # Set limits and labels\n",
    "        ax.set_xlim(xLimits)\n",
    "        ax.set_ylim(yLimits)\n",
    "\n",
    "        # Set log scale\n",
    "        ax.set_xscale(\"log\")\n",
    "\n",
    "        # Set axis labels\n",
    "        ax.set_xlabel(xAxisLabel, ha='right',x=1.0)\n",
    "        ax.set_ylabel(yAxisLabel, ha='right', y=1.0)\n",
    "\n",
    "\n",
    "        # Add grid and custom tick markers\n",
    "        ax.grid(True)\n",
    "        tickList = [1,2,3,4,5,6,7,8,9,\n",
    "        10,20,30,40,50,60,70,80,90,\n",
    "        100,200,300,400,500,600,700,800,900,\n",
    "        1000,2000,3000,4000,5000,6000,7000,8000,9000,\n",
    "        10000]\n",
    "        ax.set_xticks(tickList[tickList.index(xLimits[0]):tickList.index(xLimits[1])])\n",
    "        ax.set_xticklabels(tickList[tickList.index(xLimits[0]):tickList.index(xLimits[1])])\n",
    "        plt.xticks(rotation=45)\n",
    "\n",
    "        # Add ATLAS label\n",
    "        hep.atlas.text(\"Internal\",ax=ax)\n",
    "\n",
    "        f.savefig(dfPath+\"_\"+xAxisUnit+\".pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "funny-synthetic",
   "metadata": {},
   "source": [
    "### Resolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "textile-appreciation",
   "metadata": {},
   "outputs": [],
   "source": [
    "listOfPaths = [\n",
    "                \"/home/pekman/TLA/TH3Files/v14/merged_mc16d_mjj_v14.root\",\n",
    "                \"/home/pekman/TLA/TH3Files/v19/merged_mc16a_mjj_v19.root\",\n",
    "                ]\n",
    "\n",
    "f, axisList = plt.subplots(2,1,figsize=(400/60,300/60), dpi=60,sharex=True, gridspec_kw={'height_ratios': [2, 1]})\n",
    "ax=axisList[0]\n",
    "\n",
    "color_list=[\"black\",\"grey\"]\n",
    "\n",
    "linspace=np.linspace(x[0],x[-1],num=10000)\n",
    "\n",
    "def resolutionFunc(x,a,b,c):\n",
    "    return np.sqrt((a/np.sqrt(x))**2+(b/x)**2+c**2)\n",
    "\n",
    "\n",
    "for i,path in enumerate(listOfPaths):\n",
    "    # Get data information based on root file path and TH3 name\n",
    "    DataOrMC = isItDataOrMC(rootFilePath)\n",
    "    OnlineOrOffline = isItOnlineOrOffline(rootFilePath)\n",
    "    print(DataOrMC,OnlineOrOffline)\n",
    "    continue\n",
    "    \n",
    "    # Assign data from dataframe\n",
    "    x=df[\"x\"].loc[TH3Name]\n",
    "    y=df[\"sigmaOverY\"].loc[TH3Name]\n",
    "    x_error=df[\"xError\"].loc[TH3Name]\n",
    "    y_error=df[\"sigmaOverYError\"].loc[TH3Name]\n",
    "    \n",
    "    ax.errorbar(x, y, yerr=y_error, xerr=x_error,\n",
    "                linestyle='None',\n",
    "                marker=\"o\",\n",
    "                color=color_list[i],\n",
    "                markersize=marker_size,\n",
    "                linewidth=0.5,\n",
    "                label=path.split(\"/\")[-1].split(\"_\")[1]+OnlineOrOffline)\n",
    "\n",
    "    popt_resolutionFunc, pcov_resolutionFunc = curve_fit(resolutionFunc, x, y, sigma=y_error)\n",
    "\n",
    "    \n",
    "    ax.plot(linspace, resolutionFunc(linspace,*popt_resolutionFunc), lw=1, label=path.split(\"/\")[-1].split(\"_\")[1]+OnlineOrOffline+\" Fit\",color=color_list[i])\n",
    "\n",
    "ax.plot(linspace[240:], resolutionFunc(linspace[240:],0.27,10.6,0.039), lw=1, label=r'2016 Online Fit',color=\"blue\")\n",
    "ax.plot(linspace[:240], resolutionFunc(linspace[:240],0.27,10.6,0.039), lw=1, label=r'2016 Extrapolated Fit',color=\"blue\",linestyle='dashed')\n",
    "\n",
    "\n",
    "# Legend\n",
    "leg = ax.legend(borderpad=0.5, frameon=True, loc=1,ncol=2,facecolor=\"white\",framealpha=1.0)\n",
    "leg._legend_box.align = \"right\"\n",
    "\n",
    "#ax.set_xlabel(r\"Truth $m_{jj}$ [GeV]\", ha='right', x=1.0)\n",
    "ax.set_ylabel(r'$m_{jj}$ Resolution', ha='right', y=1.0)\n",
    "#leg.set_title(\"Online small-R jets: \"+\"$\\eta$ = \"+str(currentSlice)+\", $y^{*}<0.6$\")#+\"\\nFit range:[\"+str(round(x[0],0))+\", \"+str(round(x[-1],0))+\"] GeV\")\n",
    "leg.set_title(\"Online vs. Offline Resolution\")\n",
    "hep.atlas.text(\"Simulation Internal\",ax=ax)\n",
    "\n",
    "ax.set_xlim(100,5000)\n",
    "#ax1.set_ylim(pp[\"scaleDict\"][TH3Name][\"yMin\"],pp[\"scaleDict\"][TH3Name][\"yMax\"])\n",
    "ax.set_xscale(\"log\")\n",
    "ax.set_ylim(0.02,0.2)\n",
    "\n",
    "ax.grid()\n",
    "\n",
    "ax=axisList[1]\n",
    "\n",
    "ax.errorbar(x_list[0], y_list[0]/y_list[1],\n",
    "            linestyle='None',\n",
    "            marker=\"o\",\n",
    "            color=\"black\",\n",
    "            markersize=marker_size,\n",
    "            linewidth=0.5,\n",
    "            label=my_label)\n",
    "\n",
    "ax.set_xlim(100,5000)\n",
    "ax.set_ylim(0.98,1.12)\n",
    "ax.plot( [100,5000], [1.0,1.0],color=\"red\",lw=1)\n",
    "ax.plot( [100,5000], [1.1,1.1],color=\"red\",lw=1)\n",
    "\n",
    "#plt.xticks(rotation=45)\n",
    "ax.set_axisbelow(True)\n",
    "ax.set_xticks([100,400,1000,5000])\n",
    "ax.set_xticklabels([100,400,1000,5000])\n",
    "leg2 = ax.legend(borderpad=0.5, frameon=True, loc=1,ncol=2,facecolor=\"white\",framealpha=1.0)\n",
    "leg2._legend_box.align = \"right\"\n",
    "\n",
    "ax.set_xlabel(r\"Truth $m_{jj}$ [GeV]\", ha='right', x=1.0)\n",
    "ax.set_ylabel(r'$m_{jj}$ Resolution Ratio', ha='right', y=1.0)\n",
    "leg2.set_title(\"Resolution ratio mc16d/mc16a\")\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "f.savefig(\"comparison_mc16d.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "familiar-conducting",
   "metadata": {},
   "source": [
    "#### Resolution Based Binning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "coated-filing",
   "metadata": {},
   "outputs": [],
   "source": [
    "if(my_label==\"mc16d Online\"):\n",
    "    currentEdge = 531\n",
    "    bins1 = [currentEdge]\n",
    "    while (currentEdge > 100):\n",
    "        currentBinwidth = int(round( resolutionFunc(currentEdge, *popt_resolutionFunc)*currentEdge ))\n",
    "        currentEdge -= currentBinwidth\n",
    "        bins1.append(currentEdge)\n",
    "    bins1=bins1[1:]\n",
    "\n",
    "    currentEdge = 531\n",
    "    bins2 = [currentEdge]\n",
    "    while (currentEdge < 5000):\n",
    "        currentBinwidth = int(round( resolutionFunc(currentEdge, *popt_resolutionFunc)*currentEdge ))\n",
    "        currentEdge += currentBinwidth\n",
    "        bins2.append(currentEdge)\n",
    "    bins=bins1+bins2\n",
    "    bins.sort()\n",
    "    print(bins)\n",
    "\n",
    "    #Create JSON and ROOT binning\n",
    "    mjjBins = {\n",
    "        'TLAdefault':   bins,\n",
    "        'TLAlowMu'  :   []\n",
    "    }\n",
    "\n",
    "    outfile = open('mjjBins.json','w')\n",
    "    outfile.write(json.dumps(mjjBins, sort_keys=True, indent=4, separators=(',', ': ')))\n",
    "    outfile.close()\n",
    "\n",
    "    rootfile = ROOT.TFile('mjjBins.root', 'recreate')\n",
    "    mjjBins = json.load(open('mjjBins.json'))\n",
    "    hists = {}\n",
    "    for key in mjjBins:\n",
    "        if len(mjjBins[key])-1 < 1:\n",
    "            continue\n",
    "        hists[key] = ROOT.TH1F('h_'+key, ';mjj;', len(mjjBins[key])-1, array('d',mjjBins[key]))\n",
    "        hists[key].Write()\n",
    "    rootfile.Close()\n",
    "\n",
    "    #Check if JSON and root binning is the same\n",
    "    inJSON = open('mjjBins.json','r')\n",
    "    JSONBinDict = json.load(inJSON)\n",
    "    inROOT = ROOT.TFile('mjjBins.root', 'read')\n",
    "    listOfROOTBins = []\n",
    "\n",
    "    listOfKeys2 = inROOT.GetListOfKeys()\n",
    "    for key in listOfKeys2:\n",
    "        h1Name = key.GetName()\n",
    "        h1 = inROOT.Get(h1Name)\n",
    "        for j in range(1, h1.GetNbinsX()+2):\n",
    "                assert (h1.GetBinLowEdge(j) == JSONBinDict[str(key).split(\" \")[1][2:]][j-1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
